{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d53ece7",
   "metadata": {},
   "source": [
    "# Identification of encrypted images using CNN\n",
    "## Stanis≈Çaw Durka\n",
    "\n",
    "https://knowledgepit.ml/sus-2023/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bfe2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import numpy as np                   # advanced math library\n",
    "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
    "import random                        # for generating random numbers\n",
    "\n",
    "from keras.models import Sequential  # Model type to be used\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
    "from keras.utils import np_utils                         # NumPy related tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1950be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dbd3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 28   # used to compress input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ed5103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(paths: np.ndarray):\n",
    "    ret = []\n",
    "    for path in paths:\n",
    "        with Image.open(path) as img:\n",
    "#             ret.append(np.array(img))\n",
    "            ret.append(np.array(resize_img(img)))\n",
    "    return ret\n",
    "\n",
    "def resize_img(img):\n",
    "    basewidth = IMAGE_WIDTH\n",
    "    wpercent = (basewidth/float(img.size[0]))\n",
    "    hsize = int((float(img.size[1])*float(wpercent)))\n",
    "    return img.resize((basewidth,hsize), Image.Resampling.LANCZOS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fc085d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_path</th>\n",
       "      <th>encoded_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BigDataCup2022/S1/train/input/0.jpg</td>\n",
       "      <td>BigDataCup2022/S1/train/enc/0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BigDataCup2022/S1/train/input/1.jpg</td>\n",
       "      <td>BigDataCup2022/S1/train/enc/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BigDataCup2022/S1/train/input/2.jpg</td>\n",
       "      <td>BigDataCup2022/S1/train/enc/2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BigDataCup2022/S1/train/input/3.jpg</td>\n",
       "      <td>BigDataCup2022/S1/train/enc/3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BigDataCup2022/S1/train/input/4.jpg</td>\n",
       "      <td>BigDataCup2022/S1/train/enc/4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>BigDataCup2022/S1/train/input/5.jpg</td>\n",
       "      <td>BigDataCup2022/S1/train/enc/5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                           input_path                       encoded_path\n",
       "0   0  BigDataCup2022/S1/train/input/0.jpg  BigDataCup2022/S1/train/enc/0.jpg\n",
       "1   1  BigDataCup2022/S1/train/input/1.jpg  BigDataCup2022/S1/train/enc/1.jpg\n",
       "2   2  BigDataCup2022/S1/train/input/2.jpg  BigDataCup2022/S1/train/enc/2.jpg\n",
       "3   3  BigDataCup2022/S1/train/input/3.jpg  BigDataCup2022/S1/train/enc/3.jpg\n",
       "4   4  BigDataCup2022/S1/train/input/4.jpg  BigDataCup2022/S1/train/enc/4.jpg\n",
       "5   5  BigDataCup2022/S1/train/input/5.jpg  BigDataCup2022/S1/train/enc/5.jpg"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/train/train.csv')\n",
    "df.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2763f114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ./data/train/input/0.jpg\n",
       "1    ./data/train/input/1.jpg\n",
       "2    ./data/train/input/2.jpg\n",
       "3    ./data/train/input/3.jpg\n",
       "4    ./data/train/input/4.jpg\n",
       "Name: input_path, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"input_path\"] = [\"./data\" + x.removeprefix(\"BigDataCup2022/S1\") for x in df[\"input_path\"]]\n",
    "df[\"encoded_path\"] = [\"./data\" + x.removeprefix(\"BigDataCup2022/S1\") for x in df[\"encoded_path\"]]\n",
    "df.loc[:5]\n",
    "df[\"input_path\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d35ca4d",
   "metadata": {},
   "source": [
    "The training set is created from the list of pairs (X_input, X_encoded) as follows: \\\n",
    "X_train = X_in and X_enc concatenated along the second axis, \\\n",
    "and Y[i] = 1 for pairs of \".../input/i\", \".../enc/i\".\n",
    "\n",
    "Then, additional N elements are added where X_train = concat(X_in[i], X_enc[j]), Y[i] == 0, \\\n",
    "where i =/= j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0971403e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 56, 28, 3), (20000,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "create a training set of:\n",
    "X_train = | X_in  |\n",
    "          | X_enc |,\n",
    "Y_train = np.array of (0/1)\n",
    "'''\n",
    "def create_training_set(N = 10000):\n",
    "    X1 = np.array(get_images(df[\"input_path\"][:N]))\n",
    "    X2 = np.array(get_images(df[\"encoded_path\"][:N]))\n",
    "\n",
    "    X_train = np.concatenate((X1, X2), axis = 1)\n",
    "    Y_train = np.ones(X_train.shape[0])  # for all of the images in the training set, encoded_i == encode(input_i) \n",
    "\n",
    "    XY = list(zip(X1, X2, Y_train))\n",
    "\n",
    "    XY_2 = []\n",
    "    for i in range(len(XY)):\n",
    "        XY_2.append(XY[i])\n",
    "\n",
    "    # now, append the tuple (X_in[i], X_enc[i], 1) set with additional N elements of:\n",
    "    #                        (X_in[i], X_in[j], 0), where i != j\n",
    "    for i in range (len(XY)):\n",
    "        j = np.random.randint(len(XY))\n",
    "        if (j == i):\n",
    "            j = i+1\n",
    "        XY.append((XY[i][0], XY[j][1], 0))\n",
    "    \n",
    "    random.shuffle(XY) # shuffle the tuple so that the y's aren't equal to [1,1,1,...,1,0,...,0]\n",
    "    \n",
    "    # finally, convert the array into X_train == concat(X_in, X_enc), and Y_train:\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for i in range (len(XY)):\n",
    "        X_train.append(np.concatenate((XY[i][0],XY[i][1]), axis=0))\n",
    "        Y_train.append(XY[i][2])\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    return (X_train, Y_train)\n",
    "\n",
    "X_train, Y_train = create_training_set()\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "535dfe50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 56, 28, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ef47e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "473332c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_width = IMAGE_WIDTH):\n",
    "    model = Sequential()                                 # Linear stacking of layers\n",
    "\n",
    "    # Convolution Layer 1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(img_width*2, img_width, 3))) # 32 different 3x3 kernels -- so 32 feature maps\n",
    "    model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "    convLayer01 = Activation('relu')                     # activation\n",
    "    model.add(convLayer01)\n",
    "\n",
    "    # Convolution Layer 2\n",
    "    model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
    "    model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "    model.add(Activation('relu'))                        # activation\n",
    "    convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "    model.add(convLayer02)\n",
    "\n",
    "    # Convolution Layer 3\n",
    "    model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
    "    model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "    convLayer03 = Activation('relu')                     # activation\n",
    "    model.add(convLayer03)\n",
    "\n",
    "    # Convolution Layer 4\n",
    "    model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
    "    model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "    model.add(Activation('relu'))                        # activation\n",
    "    convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "    model.add(convLayer04)\n",
    "    model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
    "\n",
    "    # Fully Connected Layer 5\n",
    "    model.add(Dense(512))                                # 512 FCN nodes\n",
    "    # model.add(BatchNormalization())                      # normalization\n",
    "    model.add(Activation('relu'))                        # activation\n",
    "\n",
    "    # Fully Connected Layer 6                       \n",
    "    model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
    "    model.add(Dense(1))                                 # final 10 FCN nodes\n",
    "    model.add(Activation('sigmoid'))                     # sigmoid activation\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a329bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 54, 26, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 54, 26, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 54, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 52, 24, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 52, 24, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 52, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 26, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 24, 10, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 24, 10, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 24, 10, 64)        0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 22, 8, 64)         36928     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 22, 8, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 22, 8, 64)         0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 11, 4, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 2816)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               1442304   \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,509,153\n",
      "Trainable params: 1,508,769\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ebb2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c026ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "313/313 [==============================] - 47s 148ms/step - loss: 0.7669 - accuracy: 0.5174\n",
      "Epoch 2/6\n",
      "313/313 [==============================] - 48s 155ms/step - loss: 0.4948 - accuracy: 0.7453\n",
      "Epoch 3/6\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.3008 - accuracy: 0.8815\n",
      "Epoch 4/6\n",
      "313/313 [==============================] - 47s 151ms/step - loss: 0.2292 - accuracy: 0.9140\n",
      "Epoch 5/6\n",
      "313/313 [==============================] - 47s 151ms/step - loss: 0.1949 - accuracy: 0.9297\n",
      "Epoch 6/6\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 0.1752 - accuracy: 0.9389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcde2f79f00>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=64, epochs=6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "022c9af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 47s 149ms/step - loss: 0.1476 - accuracy: 0.9471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcde1f05d80>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train, Y_train, batch_size=64, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "228acbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 3) (10000, 28, 28, 3)\n",
      "x test  (10000, 56, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "def create_X_test(N = 10000):\n",
    "    df = pd.read_csv('./data/test/test.csv')\n",
    "    df[\"input_path\"] = [\"./data\" + x.removeprefix(\"BigDataCup2022/S1\") for x in df[\"input_path\"]]\n",
    "    df[\"encoded_path\"] = [\"./data\" + x.removeprefix(\"BigDataCup2022/S1\") for x in df[\"encoded_path\"]]\n",
    "    X1 = np.array(get_images(df[\"input_path\"][:N]))\n",
    "    X2 = np.array(get_images(df[\"encoded_path\"][:N])) \n",
    "    print(X1.shape, X2.shape)\n",
    "    X_test = np.concatenate((X1, X2), axis = 1)\n",
    "    return X_test\n",
    "\n",
    "X_test = create_X_test()\n",
    "\n",
    "print(\"x test \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81ebfc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 17s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "# predicted_vec = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3772ec78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 36s 58ms/step - loss: 0.5329 - accuracy: 0.8061\n"
     ]
    }
   ],
   "source": [
    "# score = model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2248432",
   "metadata": {},
   "source": [
    "# Create predictions for the test set with the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c164c33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "def predict(model, X):\n",
    "    predicted_vec = model.predict(X)\n",
    "    predictions01 = np.array([ 0 if x <= 0.5 else 1 for x in predicted_vec ])\n",
    "    return predictions01\n",
    "\n",
    "y = predict(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fb0d810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "129813f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output(predictions):\n",
    "    f = open(\"predictions.txt\", \"x\")  \n",
    "    for p in predictions:\n",
    "        f.write(str(p))\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "create_output(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c1f59abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "207/207 [==============================] - 17s 77ms/step - loss: 0.8179 - accuracy: 0.5032\n",
      "Epoch 2/5\n",
      "207/207 [==============================] - 16s 78ms/step - loss: 0.6809 - accuracy: 0.5500\n",
      "Epoch 3/5\n",
      "207/207 [==============================] - 16s 79ms/step - loss: 0.5068 - accuracy: 0.7485\n",
      "Epoch 4/5\n",
      "207/207 [==============================] - 16s 79ms/step - loss: 0.3638 - accuracy: 0.8445\n",
      "Epoch 5/5\n",
      "207/207 [==============================] - 17s 80ms/step - loss: 0.3061 - accuracy: 0.8785\n",
      "419/419 [==============================] - 10s 25ms/step - loss: 0.2505 - accuracy: 0.9070\n",
      "Test score: 0.2505260407924652\n",
      "Test accuracy: 0.9070149064064026\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "train the model on 2/3 of the training data set, \n",
    "and test it on the remaining 1/3\n",
    "'''\n",
    "def test_model(X_train, Y_train):\n",
    "    model = create_model()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    X_train2 = X_train[:6600]\n",
    "    Y_train2 = Y_train[:6600]\n",
    "\n",
    "    X_test2 = X_train[6600:]\n",
    "    Y_test2 = Y_train[6600:]\n",
    "    model.fit(X_train2, Y_train2, batch_size=32, epochs=5, verbose=1)\n",
    "    score = model.evaluate(X_test2, Y_test2)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "test_model(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
